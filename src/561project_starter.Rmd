---
title: "Untitled"
output: html_document
---

Load the data. The data is structured as a list containing two variables, mat and var.
The data consists of climate model output at ten separate time slices for multiple climate variables.
The mat variable is a list where each element is the dataset for a single variable at a single time slice, 
stored as a matrix. The elements in the var variable are the variable names and frequencies corresponding 
to each dataset. The ith element in the var variable corresponds to the name and output frequency of
the ith element in the mat variable.

```{r}
#load("./data/High/high_train.RData")
#load("./data/Medium/med_train.RData")
#load("./data/Low/low_train.RData")
#load("./data/High/high_validate.RData")
#load("./data/Medium/med_validate.RData")
#load("./data/Low/low_validate.RData")
```

```{r}
load("C:\\Users\\Doug\\Documents\\high_train.RData")
load("C:\\Users\\Doug\\Documents\\med_train.RData")
load("C:\\Users\\Doug\\Documents\\low_train.RData")
load("C:\\Users\\Doug\\Documents\\high_validate.RData")
load("C:\\Users\\Doug\\Documents\\med_validate.RData")
load("C:\\Users\\Doug\\Documents\\low_validate.RData")
```

```{r}
# Here are the values for a single dataset
high_train$mat[[1]]
# And here are the variable names corresponding to all the datasets in high_train. The first dataset shown above corresponds to the monthly variable BURDENDUST.
high_train$var
```


Once the data is loaded, a single dataset can be plotted using image()
More information about each variable including full name and units is located at
https://www.cesm.ucar.edu/projects/community-projects/DPLE/data-sets.html

Select data and axis labels
```{r}
n=170
selected_dataset <- high_train
l <- length(selected_dataset$mat)
latitudes <- round(as.numeric(colnames(selected_dataset$mat[[n]])))
longitudes <- as.numeric(rownames(selected_dataset$mat[[n]]))
dataset <- selected_dataset$mat[[n]]
varname <- selected_dataset$var[n]
```

Plot
```{r}
image(dataset, main=varname, col = hcl.colors(100, "Blue-Red"),axes=FALSE, xlab="Longitude", ylab="Latitude")
axis(3, at=seq(0,1, length=7), labels=longitudes[seq(1, 288, length.out=7)],lwd=0, pos=-0.2, outer=T)
axis(2, at=seq(1,0, length=9), labels=latitudes[seq(1, 192, length.out=9)],lwd=0, pos=0)
```

First, create features and put the features and observations into a data frame.
This sample feature adds up the value of every element in the dataset, in case variables with larger
magnitude values tend to have different optimal compression levels. The sample features should be computed for
every dataset and added to the data frame, along with the classification for the dataset.

```{r}
df <- data.frame()
ds_list <- list(high_train, med_train, low_train, high_validate, med_validate, low_validate)
classifications = c("high", "med", "low")
class_index = rep(c(1, 2, 3), 2)

for (i in 1:length(ds_list)){
  l <- length(ds_list[[i]]$mat)
  sum_feature = rep(NA, l)
  for(j in 1:l){
    sum_feature[j] <- sum(ds_list[[i]]$mat[[j]])
  }
  classification = classifications[class_index[i]]
  df <- rbind(df, data.frame("sum"=sum_feature, "classification"=rep(classification, l)))
}

df$classification <- as.factor(df$classification)

# Check that the data frame has been created successfully

head(df)
tail(df)

# Append a new feature, this one is the number of zeroes in each dataset, a measure of the sparsity of the dataset.

ds_list <- list(high_train, med_train, low_train, high_validate, med_validate, low_validate)
z <- c()
for (i in 1:length(ds_list)){
  l <- length(ds_list[[i]]$mat)
  zero_feature = rep(NA, l)
  for(j in 1:l){
    zero_feature[j] <- sum(ds_list[[i]]$mat[[j]] == 0)
  }
  z <- c(z, zero_feature)
}
df <- cbind(df, data.frame("zeroes"=z))

# Check that the data frame has been updated successfully.

head(df)
tail(df)

max_train_index = length(high_train$var) + length(med_train$var) + length(low_train$var)
train_indices = 1:max_train_index
validate_indices = (max_train_index + 1):length(df$classification)
```


```{r}
for (i in 3:16){
  hist(df[,i])
  print(skewness(df[,i]))
}


```

```{r}
# Not sure if we want to do this for all of these variables????????
# Each variable has a printed skewness in the section above and the change after transformation.
for (i in 1:length(df$sum)){
  if (df[i,3] == 0){
    df[i,3] = df[i,3] +.1
  }
}
zeros.log = log(df[,3])
hist(zeros.log)
df = cbind(df, data.frame("zeros.log"=zeros.log))
skewness(df$zeros.log)
```


```{r}
for (i in 1:length(df$sum)){
  if (df[i,4] == 0){
    df[i,4] = df[i,4] +.1
  }
}

norm.log = log(df[,4])
print(skewness(norm.log))
hist(norm.log)
df = cbind(df, data.frame("norm.log"=norm.log))
print(skewness(norm.log))
```


```{r}
for (i in 1:length(df$sum)){
  if (df[i,5] == 0){
    df[i,5] = df[i,5] +.1
  }
}

min.log = log(df[,5])
hist(min.log)
df = cbind(df, data.frame("min.log"=min.log))
print(skewness(min.log))
```


```{r}

for (i in 1:length(df$sum)){
  if (df[i,6] == 0){
    df[i,6] = df[i,6] +.1
  }
}

max.log = log(df[,6])
hist(max.log)
df = cbind(df, data.frame("max.log"=max.log))
print(skewness(max.log))
```

```{r}

for (i in 1:length(df$sum)){
  if (df[i,7] == 0){
    df[i,7] = df[i,7] +.1
  }
}

q1.log = log(df[,7])
hist(q1.log)
df = cbind(df, data.frame("q1.log"=q1.log))
print(skewness(q1.log))
```

```{r}
for (i in 1:length(df$sum)){
  if (df[i,8] == 0){
    df[i,8] = df[i,8] +.1
  }
}

q3.log = log(df[,8])
hist(q3.log)
df = cbind(df, data.frame("q3.log"=q3.log))
print(skewness(q3.log))
```

```{r}
# This column isn't working, haven't spent a ton of time looking itno why yet. 

#iqr.log = log(df[,9])
#hist(iqr.log)
#summary(iqr.log)
#mean.log = log(df[,10])
#hist(mean.log)
#df = cbind(df, data.frame("mean.log"=mean.log))
```


```{r}
for (i in 1:length(df$sum)){
  if (df[i,11] == 0){
    df[i,11] = df[i,11] +.1
  }
}

med.log = log(df[,11])
hist(med.log)
df = cbind(df, data.frame("med.log"=med.log))
print(skewness(med.log))
```
```{r}

for (i in 1:length(df$sum)){
  if (df[i,12] == 0){
    df[i,12] = df[i,12] +.1
  }
}

std.log = log(df[,12])
hist(std.log)
df = cbind(df, data.frame("std.log"=std.log))
print(skewness(std.log))
```
```{r}

for (i in 1:length(df$sum)){
  if (df[i,13] == 0){
    df[i,13] = df[i,13] +.1
  }
}

range.log = log(df[,13])
hist(range.log)
df = cbind(df, data.frame("range.log"=range.log))
print(skewness(range.log))
```
```{r}

for (i in 1:length(df$sum)){
  if (df[i,14] == 0){
    df[i,14] = df[i,14] +.1
  }
}

skew.log = log(df[,14])
hist(skew.log)
df = cbind(df, data.frame("skew.log"=skew.log))
print(skewness(skew.log))
```

```{r}
for (i in 1:length(df$sum)){
  if (df[i,15] == 0){
    df[i,15] = df[i,15] +.1
  }
}


kurtosis.log = log(df[,15])
hist(kurtosis.log)
df = cbind(df, data.frame("kurtosis.log"=kurtosis.log))
print(skewness(kurtosis.log))
```
```{r}

for (i in 1:length(df$sum)){
  if (df[i,16] == 0){
    df[i,16] = df[i,16] +.1
  }
}

aboveMeanCount.log = log(df[,16])
hist(aboveMeanCount.log)
df = cbind(df, data.frame("aboveMeanCount.log"=aboveMeanCount.log))
print(skewness(aboveMeanCount.log))
```



```{r}
df[is.na(df)] <- 0
compression_train = df[1:710, ]
compression_test = df[711:980, ]
compression.tree = tree(classification~., data = compression_train)

summary(compression.tree)

plot(compression.tree)
text(compression.tree, pretty =0 )

```


```{r}
compression.pred = predict(compression.tree, compression_test, type = "class")

table(compression_test$classification, compression.pred)

(116+58+26)/(116+24+0+22+58+10+4+10+26)
```

```{r}
cv.compress = cv.tree(compression.tree, FUN = prune.tree)

plot(cv.compress$size, cv.compress$dev, type = "b", xlab = "Tree Size", ylab = "Deviance")

```



```{r}
library(maboost)
# Run with only log transformed and got same result
compress.boost = maboost(compression_train[,-2], compression_train$classification, iter = 500, nu = .02)

varplot.maboost(compress.boost)

boost.test.pred = predict(compress.boost, compression_test[,-2])
```

```{r}

test.matrix = table(compression_test[,2], boost.test.pred)
print(test.matrix)
```

```{r}
# high = high varies from 131 to 134
(140+57+30)/(134+6+10+50+30+10+30)

140/(140)

57/ (57+10+23)

30/40
```

```{r}
best.subset = regsubsets(df[,2] ~., df[,-2], nvmax = 29)
summary(best.subset)

```

```{r}
summary(best.subset)$adjr2
print(1111)
summary(best.subset)$rsq
print(1111)
summary(best.subset)$bic
```

```{r}
best.subset.sum = summary(best.subset)

which.max(best.subset.sum$adjr2)
coef(best.subset, 22)
```

```{r}
df.best.predictors = as.data.frame(cbind(df$zeroes, df$norm, df$min, df$max, df$q3, df$std, df$range, df$skew, df$kurtosis, df$aboveMeanCount, df$norm.log, df$min.log, df$max.log, df$q1.log, df$q3.log, df$med.log, df$kurtosis.log, df$aboveMeanCount.log, df$contourCount, df$contourLength, df$mean, df$zeros.log, df$classification))


```


```{r}
compression_train_best = df.best.predictors[1:710, ]
compression_test_best = df.best.predictors[711:980, ]

```

```{r}
compress.boost.best = maboost(compression_train_best[,-23], compression_train_best[,23], iter = 500, nu = .02)

varplot.maboost(compress.boost.best)

boost.test.pred.best = predict(compress.boost.best, compression_test_best[,-23])

test.matrix = table(compression_test_best[,23], boost.test.pred.best)
print(test.matrix)

```


```{r}
df.scaled = scale(df[,-2])


compression_train_scaled = df.scaled[1:710, ]
compression_test_scaled = df.scaled[711:980, ]

```

```{r}
for (i in 1:15){
  knn.pred = knn(compression_train_scaled, compression_test_scaled, compression_train[,2], k= i)
  print(table(knn.pred, compression_test[,2]))
}

```



















