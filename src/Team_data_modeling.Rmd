---
title: "Modeling"
author: "Doug Curth"
date: "12/7/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#library(Matrix)
library(dplyr)
#library(resample)
library(ISLR)
library(tree)
library(gbm)
library(MASS)
library(class)
library(e1071) 
library("leaps")

```

```{r}
rm(list=ls())
df = read.csv("C://Users//Doug//Documents//GitHub//csci561-finalproject-team2//data//df.csv")

standardized.df = read.csv("C://Users//Doug//Documents//GitHub//csci561-finalproject-team2//data//standardizeddf.csv")

```



```{r}
df[is.na(df)] <- 0
compression_train = df[1:710, ]
compression_test = df[711:980, ]

```


# Best subset selection
###########################

```{r}

best.subset = regsubsets(df[,2] ~., df[,-c(2:3)], nvmax = 39)
summary(best.subset)

```

```{r}
summary(best.subset)$adjr2
print(1111)
summary(best.subset)$rsq
print(1111)
summary(best.subset)$bic
print(1111)
summary(best.subset)$cp
```
```{r}
plot(summary(best.subset)$adjr2)
plot(summary(best.subset)$rsq)
plot(summary(best.subset)$bic)
plot(summary(best.subset)$cp)
```

```{r}
best.subset.sum = summary(best.subset)

which.min(best.subset.sum$bic)
which.min(best.subset.sum$cp)

```

```{r}
# BIC best subset
coef(best.subset, 13)
```

```{r}
#Cp best subset
coef(best.subset, 23)

```

```{r}
bic_select = df[ ,colnames(df) %in% c('zeroes', 'med', 'entropy', 'zeros.log', 'min.log', 'max.log', 'q1.log', 'q3.log', 'skew.log', 'kertosis.log', 'aboveMeanCount.log', 'contourCountLSD', 'Varpool_75x25_MaxStat')]

cp_select <- df[, colnames(df) %in% c( "sum", "zeroes", "q3", "entropy", "zeros.log", "norm.log", "min.log", "max.log", "q1.log", "q3.log", "std.log","range.log", "skew.log", "kurtosis.log", "aboveMeanCount.log", "contourCountLSD", "contourLengthLSD","VarPool_75x25_MaxStat", "StdPool_75x25_VarStat", "VarPool_75x25_StdStat", "VarPool_75x25_MeanStat", "iqr", "range")]

```


# Standardized best subset selection
#################################
# Classification column is different in standardized df

```{r}
best.subset.std = regsubsets(standardized.df[,14] ~., standardized.df[,-c(14:15)], nvmax = 34)
summary(best.subset)

```
```{r}
summary(best.subset.std)$adjr2
print(1111)
summary(best.subset.std)$rsq
print(1111)
summary(best.subset.std)$bic
print(1111)
summary(best.subset.std)$cp
```

```{r}
plot(summary(best.subset.std)$adjr2)
plot(summary(best.subset.std)$rsq)
plot(summary(best.subset.std)$bic)
plot(summary(best.subset.std)$cp)
```

```{r}
# BIC best subset
which.min(summary(best.subset.std)$bic)
coef(best.subset.std, 16)
```

```{r}
#Cp best subset
which.min(summary(best.subset.std)$cp)
coef(best.subset, 21)

```


###############################
#standardized subset variable df
################################

```{r}
bic_std_select = df[ ,colnames(df) %in% c("kurtosis", "aboveMeanCount", "entropy", "zeros.log", "norm.log", "min.log", "max.log", "q1.log",
          "q3.log", "med.log", "std.log", "skew.log", "aboveMeanCount.log", "contourAvgLengthLSD", "VarPool_75x25_StdStat", "range")]


cp_std_select <- df[, colnames(df) %in% c( "zeroes", "q3", "std", "entropy", "zeros.log", "norm.log", "min.log","max.log", "q1.log", "q3.log", "skew.log","kurtosis.log", "aboveMeanCount.log", "contourCountLSD", "contourLengthLSD","VarPool_75x25_MaxStat", "StdPool_75x25_VarStat", "VarPool_75x25_StdStat", "VarPool_75x25_MeanStat", "iqr", "range")]

```



BIC non-standardized selection


```{r}
compression_train_bic = bic_select[1:710, ]
compression_test_bic = bic_select[711:980, ]

```


Boosted model on BIC selected data

```{r}
library(maboost)
# Run with only log transformed and got same result
compress.boost = maboost(compression_train_bic, compression_train$classification, iter = 500, nu = .02)

varplot.maboost(compress.boost)

boost.test.pred = predict(compress.boost, compression_test_bic)


```

```{r}

test.matrix = table(compression_test$classification, boost.test.pred)
print(test.matrix)
```

cp to compare to BIC subset

```{r}

compression_train_cp = cp_select[1:710, ]
compression_test_cp = cp_select[711:980, ]

```



Boosted model on CP selected data

```{r}
compress.boost = maboost(compression_train_cp, compression_train$classification, iter = 500, nu = .02)

varplot.maboost(compress.boost)

boost.test.pred = predict(compress.boost, compression_test_cp)
```


```{r}

test.matrix = table(compression_test$classification, boost.test.pred)
print(test.matrix)
```


```{r}
compression_train_bic_std = bic_std_select[1:710, ]
compression_test_bic_std = bic_std_select[711:980, ]

```

```{r}
compress.boost = maboost(compression_train_bic_std, compression_train$classification, iter = 300, nu = .002)

varplot.maboost(compress.boost)

boost.test.pred = predict(compress.boost, compression_test_bic_std)
```

```{r}

test.matrix = table(compression_test$classification, boost.test.pred)
print(test.matrix)
```



```{r}
compression_train_cp_std = cp_std_select[1:710, ]
compression_test_cp_std = cp_std_select[711:980, ]

```

```{r}
compress.boost = maboost(compression_train_cp_std, compression_train$classification, iter = 500, nu = .02)

varplot.maboost(compress.boost)

boost.test.pred = predict(compress.boost, compression_test_cp_std)
```




```{r}

test.matrix = table(compression_test$classification, boost.test.pred)
print(test.matrix)
```



KNN on standardized data
Removing NA's
```{r}
standardized.df[is.na(standardized.df)] = 0
```

```{r}

compression_train_std = standardized.df[1:710, ]
compression_test_std = standardized.df[711:980, ]

```

















```{r}
for (i in 1:15){
  knn.pred = knn(compression_train_std[,-14], compression_test_std[,-14], compression_train_std$classification, k = i)
  print(table(knn.pred, compression_test_std$classification))
}

# k = 2 is highest preforming
```









