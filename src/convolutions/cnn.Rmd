---
title: "Applying Convolutional Neural Networks"
author: "Team 2"
date: "12/06/2021"
output: pdf_document
---

# Libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(e1071) 
library(keras)
library(tensorflow)
```

# Load Data
```{r}
load("./data/High/high_train.RData")
load("./data/Medium/med_train.RData")
load("./data/Low/low_train.RData")
load("./data/High/high_validate.RData")
load("./data/Medium/med_validate.RData")
load("./data/Low/low_validate.RData")
```

# Applying a Convolutional Network

Convolutions and max pooling in R: https://rpubs.com/eR_ic/conv_pools.

Here are a few things we need to know first about the images we are dealing with:

  - All images have dimensions 288 x 192
  - All images  have 1 depth of 1 (binary).
  - We visualize this 1 dimensional range of values on a red-blue color scale.
  - The range of values for each image differs by the type of data
  - Number of images per dataset are as follows:
    - low_train: 110
    - med_train: 240
    - high_train: 360
    - low_validate: 40
    - med_validate: 90
    - high_validate: 140
  - Therefore there are a total of 980 images (270 validation + 710 training)

In order to perform convolutions we will need to. . .

  1. Normalize the pixel values in each image by
   - Adjusting the range to have a 0 minimum
   - Divide by maximum value in each image

  2. Reshape the data into single arrays for training, testing, and validation.

  3. Convolution Neural Network + Pooling 
    - https://stackoverflow.com/questions/43485361/whats-the-difference-between-conv-layer-and-pooling-layer-in-cnn/43491146
   


## Normalize

```{r}
#Normalize the data.

#Function that takes in a single image input (288x192 pixels) and rescales pixels to go 0 to max-min and normalizes them dividing by max-min.
normalize_image_pixels <- function(image){
  
  #Get the minumum value.
  min_val = min(image)

  #Subtract the lowest value from each value in the entire image.
  #This will make it so that the range of values is from 0 to (max - min).
  image = image - min_val

  #Get the new max value.
  max_val = max(image)

  #Divide the pixel values by the max value and return the result
  return(image / max_val)

}

#Normalize the data in the training and validation images. 
low_train_norm = low_train
for (i in 1:length(low_train_norm$mat)){
  low_train_norm$mat[[i]] = normalize_image_pixels(low_train_norm$mat[[i]])
}

med_train_norm = med_train
for (i in 1:length(med_train_norm$mat)){
  med_train_norm$mat[[i]] = normalize_image_pixels(med_train_norm$mat[[i]])
}

high_train_norm = high_train
for (i in 1:length(high_train_norm$mat)){
  high_train_norm$mat[[i]] = normalize_image_pixels(high_train_norm$mat[[i]])
}

low_validate_norm = low_validate
for (i in 1:length(low_validate_norm$mat)){
  low_validate_norm$mat[[i]] = normalize_image_pixels(low_validate_norm$mat[[i]])
}

med_validate_norm = med_validate
for (i in 1:length(med_validate_norm$mat)){
  med_validate_norm$mat[[i]] = normalize_image_pixels(med_validate_norm$mat[[i]])
}

high_validate_norm = high_validate
for (i in 1:length(high_validate_norm$mat)){
  high_validate_norm$mat[[i]] = normalize_image_pixels(high_validate_norm$mat[[i]])
}

```


## Reshape

```{r}
#Get normalized dataset lengths
lt = length(low_train_norm$mat)
mt = length(med_train_norm$mat)
ht = length(high_train_norm$mat)
lv = length(low_validate_norm$mat)
mv = length(med_validate_norm$mat)
hv = length(high_validate_norm$mat)

#Get pixel values
training_images = c(low_train_norm$mat, med_train_norm$mat, high_train_norm$mat)
validation_images = c(low_validate_norm$mat, med_validate_norm$mat, high_validate_norm$mat)

#Reshape data into single array
training_images_rs = array_reshape(training_images, c(lt+mt+ht, 288, 192, 1))
validation_images_rs = array_reshape(validation_images, c(lv+mv+hv, 288, 192, 1))

```


## CNN

```{r}
#Instantiate the convolution
model <- keras_model_sequential() %>%
  # adding the first convolution layer with 64 3by3 filter
  # we add a color depth of 1 since convolutions operate over 3D tensors
  layer_conv_2d(input_shape = c(288, 192, 1), filters = 1, kernel_size = c(5,5), activation = 'relu') %>%
  # adding a max pooling layer which halves the dimensions
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  # adding a second convolution layer which filters the results
  # from the previous layer
  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = 'relu') %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%

  # Now flatten the output.
  layer_flatten() %>% 
  # After this you'll just have the same DNN structure as the non convolutional version
  layer_dense(units = 16, activation = 'relu') %>% 
  layer_dense(units = 10, activation = 'softmax')

model %>% compile(
  loss = 'sparse_categorical_crossentropy',
  optimizer = optimizer_adam(),
  metrics = c('accuracy')

)
model %>% summary()

```